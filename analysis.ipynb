{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lightjob.cli import load_db\n",
    "from lightjob.db import SUCCESS, RUNNING\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyearth import Earth\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score, KFold, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.base import clone\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import json\n",
    "import collections\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "%matplotlib inline\n",
    "\n",
    "class EarthOneVsRestClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        pipeline = Pipeline([\n",
    "                ('earth', (Earth(**params))),\n",
    "                ('logistic', LogisticRegression())\n",
    "            ])\n",
    "        self.clf = OneVsRestClassifier(pipeline)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "class EnsembleRegressor(object):\n",
    "    def __init__(self, regs=None):\n",
    "        self.regs = regs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, return_std=False):\n",
    "        if return_std:\n",
    "            means = []\n",
    "            stds = []\n",
    "            for r in self.regs:\n",
    "                m, s = r.predict(X, return_std=True)\n",
    "                means.append(m)\n",
    "                stds.append(s)\n",
    "            means = np.vstack(means).T\n",
    "            stds = np.vstack(stds).T\n",
    "            return np.mean(means, axis=1), (np.sqrt((stds**2).sum(axis=1)) / stds.shape[1])\n",
    "        else:\n",
    "            preds = np.vstack([r.predict(X) for r in self.regs]).T\n",
    "            return np.mean(preds, axis=1)\n",
    "\n",
    "\n",
    "def plot_imp(names, values):\n",
    "    ind = (np.arange(len(names)))\n",
    "    plt.xticks(ind + 0.5, names)\n",
    "    plt.bar(ind, values, width=1)\n",
    "    plt.xlabel('variable index')\n",
    "    plt.ylabel('importance')\n",
    "\n",
    "    \n",
    "def mse(model, X, y):\n",
    "    m = model\n",
    "    return ((m.predict(X) - y)**2).mean() \n",
    "\n",
    "def acc(model, X, y):\n",
    "    return (model.predict(X) == y).mean()\n",
    "\n",
    "def evaluate(model, X, y, score=mse):\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    models = []\n",
    "    for train, test in KFold(X.shape[0], n_folds=2, shuffle=True, random_state=4):\n",
    "        m = clone(model)\n",
    "        m.fit(X[train], y[train])\n",
    "        train_scores.append(score(m, X[train], y[train]) )\n",
    "        test_scores.append(score(m, X[test], y[test]) )\n",
    "        models.append(m)\n",
    "    train_scores = np.array(train_scores)\n",
    "    test_scores = np.array(test_scores)\n",
    "    return models, train_scores, test_scores\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def smooth_image(x, y, z, w=100, h=100, model=SVR()):\n",
    "    X = np.vstack((x, y)).T\n",
    "    model.fit(X, z)\n",
    "    x, y = np.meshgrid(\n",
    "        np.linspace(x.min(), x.max(), w),\n",
    "        np.linspace(y.min(), y.max(), h)\n",
    "    )\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    xs = np.vstack((x, y)).T\n",
    "    zs = model.predict(xs)\n",
    "    zs = zs.reshape((w, h))\n",
    "    return zs\n",
    "\n",
    "def flatten_dict(l):\n",
    "    d = {}\n",
    "    for k, v in l.items():\n",
    "        if isinstance(v, collections.Mapping):\n",
    "            d.update(flatten_dict(v))\n",
    "        elif isinstance(v, list) or isinstance(v, tuple):\n",
    "            for i, l in enumerate(v):\n",
    "                d[k+'_{}'.format(i)] = l\n",
    "        else:\n",
    "            d[k] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = load_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs = db.jobs_with(state=SUCCESS)\n",
    "jobs = list(jobs)\n",
    "jobs = filter(lambda j:j['content']['dataset']=='mnist', jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1e688b5fa673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "stats = defaultdict(list)\n",
    "for j in jobs:\n",
    "\n",
    "    for k, v in j['content']['model'].items():\n",
    "        stats[k].append(v)\n",
    "    \n",
    "    if j['hist'] is not None:  \n",
    "        for h in j['hist'][0].keys():\n",
    "            d = [a[h] for a in j['hist']]\n",
    "            stats[h].append(d)\n",
    "    stats['summary'].append(j['summary'])\n",
    "    stats['where'].append(j['where'])\n",
    "df = pd.DataFrame(stats)\n",
    "\n",
    "df['last_g_loss'] = df['g_loss'].apply(lambda l:l[-1])\n",
    "df['last_d_loss'] = df['d_loss'].apply(lambda l:l[-1])\n",
    "df['min_g_loss'] = df['g_loss'].apply(lambda l:np.min(l))\n",
    "df['min_d_loss'] = df.apply(lambda c:c['d_loss'][np.argmin(c['g_loss'])], axis=1)\n",
    "df['ratio_loss'] = df['last_g_loss'] / df['last_d_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = df.sort_values(by='ratio_loss', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "summaries = df['summary']\n",
    "for s in summaries:\n",
    "    filename = 'results/{}/samples00100.png'.format(s)\n",
    "    print(filename)\n",
    "    display(Image(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_x = df[['num_filters_d', 'num_filters_g', 'scale', 'do_batch_norm', 'start_w', 'start_h', 'filter_size', 'where']]\n",
    "df_x = pd.get_dummies(df_x)\n",
    "colnames = df_x.columns\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_x.values\n",
    "y = df[['last_d_loss']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "   'Earth': Earth(max_degree=2, max_terms=10, \n",
    "                  smooth=False, thresh=0, minspan=1, \n",
    "                  check_every=1,\n",
    "                  verbose=0,\n",
    "                  feature_importance_type='rss',\n",
    "                  endspan=1),\n",
    "    'RandomForestRegressor': RandomForestRegressor(max_depth=20, n_estimators=10),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'DummyRegressor': DummyRegressor(),\n",
    "}\n",
    "result = {}\n",
    "cols = defaultdict(list)\n",
    "for name, m in models.items():\n",
    "    models, train, valid = evaluate(m, X_train, y_train)\n",
    "    cols['model'].append(m.__class__.__name__)\n",
    "    cols['train_mean'].append(train.mean())\n",
    "    cols['train_std'].append(train.std())\n",
    "    cols['valid_mean'].append(valid.mean())\n",
    "    cols['valid_std'].append(valid.std())\n",
    "    #cols['test'].append\n",
    "    result[name] = models\n",
    "#earth = models[0]\n",
    "#earth.fit(X, y)\n",
    "results = pd.DataFrame(cols)\n",
    "results = results.sort_values(by='valid_mean')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_model = result[results.iloc[0]['model']][0]\n",
    "mse(last_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin = result['LinearRegression'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for imp in lin.coef_:\n",
    "    indices = range(len(imp))\n",
    "    low = sorted(indices, key=lambda i:imp[i])\n",
    "    low = low[0:4]\n",
    "    high = sorted(indices, key=lambda i:-imp[i])\n",
    "    high = high[0:4]\n",
    "    indices = low + high\n",
    "    names = colnames\n",
    "    names = map(lambda i:names[i], indices)\n",
    "    imp = map(lambda i:imp[i], indices)\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    plot_imp(names, imp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "earth = result['earth'][0]\n",
    "print(earth.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "plot_imp(colnames, earth.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By using images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://127.0.0.1:20000/export_data?type=classification&class=gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = set()\n",
    "for i in range(len(df)):\n",
    "    h = df['hypers'].iloc[i]\n",
    "    h = json.loads(h)\n",
    "    h = flatten_dict(h)\n",
    "    colnames |= set(h.keys())\n",
    "colnames = list(colnames)\n",
    "print(colnames)\n",
    "for col in colnames:\n",
    "    df[col] = df.apply(lambda r:flatten_dict(json.loads(r['hypers'])).get(col), axis=1)\n",
    "#df['nb_filters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = colnames\n",
    "x_df = df[cols]\n",
    "y_df = df['label'].copy()\n",
    "\n",
    "\"\"\"\n",
    "y_df[y_df == 'excellent'] = '+'\n",
    "y_df[y_df == 'good'] = '+'\n",
    "y_df[y_df == 'okay'] = '+'\n",
    "y_df[y_df == 'bad'] = '-'\n",
    "y_df[y_df == 'very_bad'] = '-'\n",
    "\"\"\"\n",
    "\n",
    "x_df = pd.get_dummies(x_df, columns=cols)\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = x_df.values\n",
    "y = y_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "   'EarthOneVsRestClassifier': EarthOneVsRestClassifier(max_degree=2, max_terms=10, \n",
    "                  smooth=False, thresh=0, minspan=1, \n",
    "                  check_every=1,\n",
    "                  verbose=0,\n",
    "                  feature_importance_type='rss',\n",
    "                  endspan=1),\n",
    "    'RandomForestClassifier': RandomForestClassifier(max_depth=20, n_estimators=10),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'DummyClassifier': DummyClassifier(),\n",
    "}\n",
    "result = {}\n",
    "cols = defaultdict(list)\n",
    "for name, m in models.items():\n",
    "    models, train, valid = evaluate(m, X_train, y_train, score=acc)\n",
    "    cols['model'].append(m.__class__.__name__)\n",
    "    cols['train_mean'].append(train.mean())\n",
    "    cols['train_std'].append(train.std())\n",
    "    cols['valid_mean'].append(valid.mean())\n",
    "    cols['valid_std'].append(valid.std())\n",
    "    #cols['test'].append\n",
    "    result[name] = models\n",
    "#earth = models[0]\n",
    "#earth.fit(X, y)\n",
    "results = pd.DataFrame(cols)\n",
    "results = results.sort_values(by='valid_mean', ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(best_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model = result[results.iloc[0]['model']][0]\n",
    "acc(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(best_model.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
